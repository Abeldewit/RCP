{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_csv(open('clean_positive_train.csv','r'), encoding='utf-8', engine='c')\n",
    "df_neg = pd.read_csv(open('clean_negative_train.csv','r'), encoding='utf-8', engine='c')\n",
    "\n",
    "df_pos['text'] = df_pos['text'].astype(str)\n",
    "df_pos['parent_text'] = df_pos['parent_text'].astype(str)\n",
    "\n",
    "df_neg['text'] = df_neg['text'].astype(str)\n",
    "df_neg['parent_text'] = df_neg['parent_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>198.448509</td>\n",
       "      <td>198.448509</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>369.154003</td>\n",
       "      <td>369.154003</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>256.498200</td>\n",
       "      <td>256.498200</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>530.071252</td>\n",
       "      <td>530.071252</td>\n",
       "      <td>0.026449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8907.000000</td>\n",
       "      <td>-8907.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>201.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4865.000000</td>\n",
       "      <td>4865.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9531.000000</td>\n",
       "      <td>9531.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score           ups  controversiality  parent_score  \\\n",
       "count  49999.000000  49999.000000      49999.000000  49999.000000   \n",
       "mean     198.448509    198.448509          0.000020    369.154003   \n",
       "std      256.498200    256.498200          0.004472    530.071252   \n",
       "min       66.000000     66.000000          0.000000  -8907.000000   \n",
       "25%       83.000000     83.000000          0.000000     84.000000   \n",
       "50%      116.000000    116.000000          0.000000    185.000000   \n",
       "75%      201.000000    201.000000          0.000000    419.000000   \n",
       "max     4865.000000   4865.000000          1.000000   9531.000000   \n",
       "\n",
       "         parent_ups  parent_controversiality  \n",
       "count  49999.000000             49999.000000  \n",
       "mean     369.154003                 0.000700  \n",
       "std      530.071252                 0.026449  \n",
       "min    -8907.000000                 0.000000  \n",
       "25%       84.000000                 0.000000  \n",
       "50%      185.000000                 0.000000  \n",
       "75%      419.000000                 0.000000  \n",
       "max     9531.000000                 1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_pos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "      <td>49999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-14.564351</td>\n",
       "      <td>-14.564351</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>66.805736</td>\n",
       "      <td>66.805736</td>\n",
       "      <td>0.002740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.274812</td>\n",
       "      <td>15.274812</td>\n",
       "      <td>0.038183</td>\n",
       "      <td>216.581912</td>\n",
       "      <td>216.581912</td>\n",
       "      <td>0.052274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-634.000000</td>\n",
       "      <td>-634.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1622.000000</td>\n",
       "      <td>-1622.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14776.000000</td>\n",
       "      <td>14776.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score           ups  controversiality  parent_score  \\\n",
       "count  49999.000000  49999.000000      49999.000000  49999.000000   \n",
       "mean     -14.564351    -14.564351          0.001460     66.805736   \n",
       "std       15.274812     15.274812          0.038183    216.581912   \n",
       "min     -634.000000   -634.000000          0.000000  -1622.000000   \n",
       "25%      -15.000000    -15.000000          0.000000      6.000000   \n",
       "50%      -10.000000    -10.000000          0.000000     15.000000   \n",
       "75%       -8.000000     -8.000000          0.000000     44.000000   \n",
       "max       -6.000000     -6.000000          1.000000  14776.000000   \n",
       "\n",
       "         parent_ups  parent_controversiality  \n",
       "count  49999.000000             49999.000000  \n",
       "mean      66.805736                 0.002740  \n",
       "std      216.581912                 0.052274  \n",
       "min    -1622.000000                 0.000000  \n",
       "25%        6.000000                 0.000000  \n",
       "50%       15.000000                 0.000000  \n",
       "75%       44.000000                 0.000000  \n",
       "max    14776.000000                 1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_neg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a small part of clean text we can start to learn the texts to our machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-634\n",
      "4865\n",
      "(79998,)\n"
     ]
    }
   ],
   "source": [
    "# First we concatenate both lists and shuffle it to scrabble positive and negative\n",
    "df = pd.concat([df_pos, df_neg])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Second we split our data for training and testing\n",
    "text_data = df['text']\n",
    "text_score = df['score']\n",
    "# parent_text_data = df['parent_text']\n",
    "# parent_text_score = df['parent_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data,text_score, test_size = 0.20, random_state = 42)\n",
    "\n",
    "print(min(y_train))\n",
    "print(max(y_train))\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "def posneg(number):\n",
    "    if number > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "y_train = y_train.apply(posneg)\n",
    "y_test = y_test.apply(posneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a tokenizer which will give a word_index integer value to each word\n",
    "tokenizer = Tokenizer(num_words=10000, lower=True, split=' ', document_count=0)\n",
    "\n",
    "# Create the word_index list based on all our data\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "\n",
    "# Now we make a list of sequences of integers based on our texts\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(X_train_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(X_test_seq,\n",
    "                                                        value=0,\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n",
      "[7462  210  368 5123   21  287   44  176    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[ 122   26  192   90  752 9054  154 1367   25  262  243 1437    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "91772\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]), len(train_data[1]))\n",
    "print(max(train_data, key=len))\n",
    "print(max(test_data, key=len))\n",
    "print(len(tokenizer.word_index) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we can do some neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          1468352   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,469,449\n",
      "Trainable params: 1,469,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(24, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79998 samples, validate on 20000 samples\n",
      "Epoch 1/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.7528 - acc: 0.5841 - val_loss: 0.6813 - val_acc: 0.5913\n",
      "Epoch 2/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.6641 - acc: 0.6109 - val_loss: 0.6678 - val_acc: 0.6018\n",
      "Epoch 3/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.6485 - acc: 0.6277 - val_loss: 0.6586 - val_acc: 0.6189\n",
      "Epoch 4/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.6358 - acc: 0.6418 - val_loss: 0.6541 - val_acc: 0.6206\n",
      "Epoch 5/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.6245 - acc: 0.6520 - val_loss: 0.6471 - val_acc: 0.6327\n",
      "Epoch 6/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.6128 - acc: 0.6636 - val_loss: 0.6413 - val_acc: 0.6425\n",
      "Epoch 7/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.6015 - acc: 0.6753 - val_loss: 0.6371 - val_acc: 0.6497\n",
      "Epoch 8/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5929 - acc: 0.6827 - val_loss: 0.6339 - val_acc: 0.6525\n",
      "Epoch 9/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5812 - acc: 0.6941 - val_loss: 0.6343 - val_acc: 0.6569\n",
      "Epoch 10/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.5731 - acc: 0.7019 - val_loss: 0.6341 - val_acc: 0.6576\n",
      "Epoch 11/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.5640 - acc: 0.7092 - val_loss: 0.6356 - val_acc: 0.6579\n",
      "Epoch 12/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5559 - acc: 0.7158 - val_loss: 0.6348 - val_acc: 0.6629\n",
      "Epoch 13/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5500 - acc: 0.7213 - val_loss: 0.6491 - val_acc: 0.6539\n",
      "Epoch 14/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5459 - acc: 0.7241 - val_loss: 0.6476 - val_acc: 0.6516\n",
      "Epoch 15/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5395 - acc: 0.7294 - val_loss: 0.6445 - val_acc: 0.6585\n",
      "Epoch 16/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5347 - acc: 0.7327 - val_loss: 0.6487 - val_acc: 0.6582\n",
      "Epoch 17/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5340 - acc: 0.7323 - val_loss: 0.6447 - val_acc: 0.6611\n",
      "Epoch 18/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5264 - acc: 0.7386 - val_loss: 0.6628 - val_acc: 0.6532\n",
      "Epoch 19/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5260 - acc: 0.7391 - val_loss: 0.6519 - val_acc: 0.6612\n",
      "Epoch 20/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5206 - acc: 0.7431 - val_loss: 0.6576 - val_acc: 0.6601\n",
      "Epoch 21/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5193 - acc: 0.7438 - val_loss: 0.6570 - val_acc: 0.6601\n",
      "Epoch 22/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5169 - acc: 0.7462 - val_loss: 0.6613 - val_acc: 0.6587\n",
      "Epoch 23/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5153 - acc: 0.7473 - val_loss: 0.6668 - val_acc: 0.6583\n",
      "Epoch 24/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5134 - acc: 0.7483 - val_loss: 0.6673 - val_acc: 0.6585\n",
      "Epoch 25/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5089 - acc: 0.7510 - val_loss: 0.6813 - val_acc: 0.6550\n",
      "Epoch 26/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5062 - acc: 0.7535 - val_loss: 0.6812 - val_acc: 0.6554\n",
      "Epoch 27/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.5032 - acc: 0.7549 - val_loss: 0.7115 - val_acc: 0.6445\n",
      "Epoch 28/40\n",
      "79998/79998 [==============================] - 2s 25us/sample - loss: 0.5027 - acc: 0.7546 - val_loss: 0.6814 - val_acc: 0.6550\n",
      "Epoch 29/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4972 - acc: 0.7585 - val_loss: 0.6876 - val_acc: 0.6543\n",
      "Epoch 30/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4964 - acc: 0.7575 - val_loss: 0.7296 - val_acc: 0.6418\n",
      "Epoch 31/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4919 - acc: 0.7592 - val_loss: 0.6986 - val_acc: 0.6561\n",
      "Epoch 32/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4813 - acc: 0.7650 - val_loss: 0.7155 - val_acc: 0.6575\n",
      "Epoch 33/40\n",
      "79998/79998 [==============================] - 2s 28us/sample - loss: 0.4762 - acc: 0.7670 - val_loss: 0.7299 - val_acc: 0.6486\n",
      "Epoch 34/40\n",
      "79998/79998 [==============================] - 2s 25us/sample - loss: 0.4668 - acc: 0.7720 - val_loss: 0.7488 - val_acc: 0.6553\n",
      "Epoch 35/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4580 - acc: 0.7741 - val_loss: 0.7859 - val_acc: 0.6514\n",
      "Epoch 36/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4513 - acc: 0.7776 - val_loss: 0.7718 - val_acc: 0.6518\n",
      "Epoch 37/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4424 - acc: 0.7831 - val_loss: 0.7955 - val_acc: 0.6520\n",
      "Epoch 38/40\n",
      "79998/79998 [==============================] - 2s 26us/sample - loss: 0.4346 - acc: 0.7866 - val_loss: 0.8272 - val_acc: 0.6420\n",
      "Epoch 39/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.4244 - acc: 0.7916 - val_loss: 0.8471 - val_acc: 0.6401\n",
      "Epoch 40/40\n",
      "79998/79998 [==============================] - 2s 27us/sample - loss: 0.4195 - acc: 0.7938 - val_loss: 0.8808 - val_acc: 0.6496\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                    y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(test_data, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
