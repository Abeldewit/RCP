{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import nltk\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = glob.glob(\"data/clean_positive_train_0.csv\")\n",
    "neg_files = glob.glob(\"data/clean_negative_train_0.csv\")\n",
    "\n",
    "df_pos_list = [pd.read_csv(open(fp, 'r'), encoding='utf-8', engine='c') for fp in pos_files[:3]]\n",
    "df_neg_list = [pd.read_csv(open(fp, 'r'), encoding='utf-8', engine='c') for fp in neg_files[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make features for each dataset that we have, calculating all these features takes a long long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>profanity</th>\n",
       "      <th>profanity_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1127.415600</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>1347.648050</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.197250</td>\n",
       "      <td>2.679215e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500013</td>\n",
       "      <td>1375.725312</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.162087</td>\n",
       "      <td>1465.051101</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>0.283466</td>\n",
       "      <td>0.397933</td>\n",
       "      <td>2.922975e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2946.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8907.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.178028e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-129.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.408572e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>820.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>783.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.238206e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2183.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2329.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.362519e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14097.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score           ups  controversiality  parent_score  \\\n",
       "count  20000.000000  20000.000000      20000.000000  20000.000000   \n",
       "mean       0.500000   1127.415600          0.000050      0.973000   \n",
       "std        0.500013   1375.725312          0.007071      0.162087   \n",
       "min        0.000000  -2946.000000          0.000000      0.000000   \n",
       "25%        0.000000   -129.000000          0.000000      1.000000   \n",
       "50%        0.500000    820.000000          0.000000      1.000000   \n",
       "75%        1.000000   2183.000000          0.000000      1.000000   \n",
       "max        1.000000   9582.000000          1.000000      1.000000   \n",
       "\n",
       "         parent_ups  parent_controversiality     sentiment     profanity  \\\n",
       "count  20000.000000             20000.000000  20000.000000  20000.000000   \n",
       "mean    1347.648050                 0.000350      0.033150      0.197250   \n",
       "std     1465.051101                 0.018705      0.283466      0.397933   \n",
       "min    -8907.000000                 0.000000     -1.000000      0.000000   \n",
       "25%      117.000000                 0.000000     -0.037500      0.000000   \n",
       "50%      783.000000                 0.000000      0.000000      0.000000   \n",
       "75%     2329.000000                 0.000000      0.160000      0.000000   \n",
       "max    14097.000000                 1.000000      1.000000      1.000000   \n",
       "\n",
       "       profanity_prob  \n",
       "count    2.000000e+04  \n",
       "mean     2.679215e-01  \n",
       "std      2.922975e-01  \n",
       "min      1.178028e-22  \n",
       "25%      8.408572e-02  \n",
       "50%      1.238206e-01  \n",
       "75%      3.362519e-01  \n",
       "max      1.000000e+00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = [pd.concat([df_pos, df_neg]) for (df_pos, df_neg) in zip(df_pos_list, df_neg_list)]\n",
    "\n",
    "# Now we have scrambeled dataframes of 20000 entries, with features such as binary scores and profanity\n",
    "df[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_text</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>profanity</th>\n",
       "      <th>profanity_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>twitter try comment article current activities</td>\n",
       "      <td>1</td>\n",
       "      <td>9582</td>\n",
       "      <td>0</td>\n",
       "      <td>fucking faggot</td>\n",
       "      <td>0</td>\n",
       "      <td>-7526</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well exactly sounds like shoebox least wheneve...</td>\n",
       "      <td>1</td>\n",
       "      <td>9531</td>\n",
       "      <td>0</td>\n",
       "      <td>elaborate cum box please</td>\n",
       "      <td>1</td>\n",
       "      <td>3841</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010472</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soviet russia bomb disarms</td>\n",
       "      <td>1</td>\n",
       "      <td>8545</td>\n",
       "      <td>0</td>\n",
       "      <td>dont live russia anymore going back time soon ...</td>\n",
       "      <td>1</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>runin senitur yolo</td>\n",
       "      <td>1</td>\n",
       "      <td>7430</td>\n",
       "      <td>0</td>\n",
       "      <td>made realize future presidents probably facebo...</td>\n",
       "      <td>1</td>\n",
       "      <td>4651</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>step motherfucker</td>\n",
       "      <td>1</td>\n",
       "      <td>7173</td>\n",
       "      <td>0</td>\n",
       "      <td>sex step mom dad around junior high school goi...</td>\n",
       "      <td>1</td>\n",
       "      <td>4251</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score   ups  \\\n",
       "0     twitter try comment article current activities      1  9582   \n",
       "1  well exactly sounds like shoebox least wheneve...      1  9531   \n",
       "2                         soviet russia bomb disarms      1  8545   \n",
       "3                                 runin senitur yolo      1  7430   \n",
       "4                                  step motherfucker      1  7173   \n",
       "\n",
       "   controversiality                                        parent_text  \\\n",
       "0                 0                                     fucking faggot   \n",
       "1                 0                           elaborate cum box please   \n",
       "2                 0  dont live russia anymore going back time soon ...   \n",
       "3                 0  made realize future presidents probably facebo...   \n",
       "4                 0  sex step mom dad around junior high school goi...   \n",
       "\n",
       "   parent_score  parent_ups  parent_controversiality  sentiment  profanity  \\\n",
       "0             0       -7526                        0   0.000000          0   \n",
       "1             1        3841                        0   0.010472          1   \n",
       "2             1         621                        0   0.000000          0   \n",
       "3             1        4651                        0   0.000000          0   \n",
       "4             1        4251                        0   0.000000          1   \n",
       "\n",
       "   profanity_prob  \n",
       "0        0.121710  \n",
       "1        0.999996  \n",
       "2        0.084165  \n",
       "3        0.120956  \n",
       "4        0.658445  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, lower=True, split=' ', document_count=0)\n",
    "# Create the word_index list based on all our data\",\n",
    "text_data = [np.array2string(df[single_df]['text'].values.astype(str)) for single_df in range(len(df))]\n",
    "text_data = ' '.join(text_data)\n",
    "tokenizer.fit_on_texts(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_data = [np.array([])]\n",
    "score_data = [np.array([])]\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for n in range(len(df)):\n",
    "    cur_df = df[n]\n",
    "    df[n].dropna(axis=0, inplace=True)\n",
    "    size = len(cur_df)\n",
    "    for index, row in cur_df.iterrows():\n",
    "        sentiment = row['sentiment']\n",
    "        profanity = row['profanity_prob']\n",
    "        features = np.hstack((sentiment, profanity))\n",
    "        if index == 0:\n",
    "            feature_data[n] = features\n",
    "            score_data[n] = row['score']\n",
    "        else:\n",
    "            feature_data[n] = np.vstack([feature_data[n], features])\n",
    "            score_data[n] = np.vstack([score_data[n], row['score']])\n",
    "        \n",
    "\n",
    "print(feature_data[0].shape)\n",
    "print(score_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(feature_data[n], text_score[n], test_size=0.20, random_state=42)\n",
    "X_train.append(X_train_tmp)\n",
    "X_test.append(X_test_tmp)\n",
    "y_train.append(y_train_tmp)\n",
    "y_test.append(y_test_tmp)\n",
    "\n",
    "X_train[n] = tf.keras.utils.normalize(X_train[n], axis=1)\n",
    "X_test[n] = tf.keras.utils.normalize(X_test[n], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we can do some neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(24, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train[0]\n",
    "\n",
    "test_data = X_test[0]\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    y_train[0],\n",
    "                    epochs=40,\n",
    "                    validation_data=(test_data, y_test[0]),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
