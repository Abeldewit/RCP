{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import nltk\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = glob.glob(\"data/clean_positive_train_*.csv\")\n",
    "neg_files = glob.glob(\"data/clean_negative_train_*.csv\")\n",
    "\n",
    "df_pos_list = [pd.read_csv(open(fp, 'r'), encoding='utf-8', engine='c') for fp in pos_files[:10]]\n",
    "df_neg_list = [pd.read_csv(open(fp, 'r'), encoding='utf-8', engine='c') for fp in neg_files[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make features for each dataset that we have, calculating all these features takes a long long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>profanity</th>\n",
       "      <th>profanity_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.940550</td>\n",
       "      <td>123.437950</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.036857</td>\n",
       "      <td>0.144450</td>\n",
       "      <td>2.213078e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500013</td>\n",
       "      <td>41.501038</td>\n",
       "      <td>0.031608</td>\n",
       "      <td>0.236471</td>\n",
       "      <td>273.303875</td>\n",
       "      <td>0.045779</td>\n",
       "      <td>0.274485</td>\n",
       "      <td>0.351554</td>\n",
       "      <td>2.556282e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-342.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.092762e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.562152e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.199541e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.229088e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5295.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score           ups  controversiality  parent_score  \\\n",
       "count  20000.000000  20000.000000      20000.000000  20000.000000   \n",
       "mean       0.500000     32.500000          0.001000      0.940550   \n",
       "std        0.500013     41.501038          0.031608      0.236471   \n",
       "min        0.000000     -9.000000          0.000000      0.000000   \n",
       "25%        0.000000     -9.000000          0.000000      1.000000   \n",
       "50%        0.500000     32.500000          0.000000      1.000000   \n",
       "75%        1.000000     74.000000          0.000000      1.000000   \n",
       "max        1.000000     74.000000          1.000000      1.000000   \n",
       "\n",
       "         parent_ups  parent_controversiality     sentiment     profanity  \\\n",
       "count  20000.000000             20000.000000  20000.000000  20000.000000   \n",
       "mean     123.437950                 0.002100      0.036857      0.144450   \n",
       "std      273.303875                 0.045779      0.274485      0.351554   \n",
       "min     -342.000000                 0.000000     -1.000000      0.000000   \n",
       "25%       10.000000                 0.000000     -0.025000      0.000000   \n",
       "50%       42.000000                 0.000000      0.000000      0.000000   \n",
       "75%      129.250000                 0.000000      0.150000      0.000000   \n",
       "max     5295.000000                 1.000000      1.000000      1.000000   \n",
       "\n",
       "       profanity_prob  \n",
       "count    2.000000e+04  \n",
       "mean     2.213078e-01  \n",
       "std      2.556282e-01  \n",
       "min      1.092762e-20  \n",
       "25%      7.562152e-02  \n",
       "50%      1.199541e-01  \n",
       "75%      2.229088e-01  \n",
       "max      1.000000e+00  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = [pd.concat([df_pos, df_neg]) for (df_pos, df_neg) in zip(df_pos_list, df_neg_list)]\n",
    "print(len(df))\n",
    "\n",
    "# Now we have scrambeled dataframes of 20000 entries, with features such as binary scores and profanity\n",
    "df[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_text</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_controversiality</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>profanity</th>\n",
       "      <th>profanity_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work guys last year confirm brightest lights c...</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>bad enough lpt never even heard link shortener...</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seems kinda useless unless live bathroom brush...</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>random button power button tv remote yes prett...</td>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.181818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously least hitler killed hitler</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>please dont refer things hitler x bad taste ea...</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont worry legitimate hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>florida suffering one two shitstorms time</td>\n",
       "      <td>1</td>\n",
       "      <td>391</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.205006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir ip adress 127001 hes good</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>start 127</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  ups  \\\n",
       "0  work guys last year confirm brightest lights c...      1   74   \n",
       "1  seems kinda useless unless live bathroom brush...      1   74   \n",
       "2               seriously least hitler killed hitler      1   74   \n",
       "3                    dont worry legitimate hurricane      1   74   \n",
       "4                      sir ip adress 127001 hes good      1   74   \n",
       "\n",
       "   controversiality                                        parent_text  \\\n",
       "0                 0  bad enough lpt never even heard link shortener...   \n",
       "1                 0  random button power button tv remote yes prett...   \n",
       "2                 0  please dont refer things hitler x bad taste ea...   \n",
       "3                 0          florida suffering one two shitstorms time   \n",
       "4                 0                                          start 127   \n",
       "\n",
       "   parent_score  parent_ups  parent_controversiality  sentiment  profanity  \\\n",
       "0             1         137                        0   0.000000          0   \n",
       "1             1         441                        0  -0.181818          0   \n",
       "2             1          71                        0  -0.250000          0   \n",
       "3             1         391                        0   0.000000          0   \n",
       "4             1          21                        0   0.700000          0   \n",
       "\n",
       "   profanity_prob  \n",
       "0        0.021070  \n",
       "1        0.059085  \n",
       "2        0.477267  \n",
       "3        0.205006  \n",
       "4        0.192113  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, lower=True, split=' ', document_count=0)\n",
    "# Create the word_index list based on all our data\",\n",
    "text_data = [np.array2string(df[single_df]['text'].values.astype(str)) for single_df in range(len(df))]\n",
    "text_data = ' '.join(text_data)\n",
    "tokenizer.fit_on_texts(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-d2a33db3d337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofanity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfeature_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mscore_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "feature_data = [np.array([])]\n",
    "score_data = [np.array([])]\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "# Iterate over each DataFrame\n",
    "for n in range(len(df)):\n",
    "    print(n)\n",
    "    cur_df = df[n]\n",
    "    df[n].dropna(axis=0, inplace=True)\n",
    "    size = len(cur_df)\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in cur_df.iterrows():\n",
    "        sentiment = row['sentiment']\n",
    "        profanity = row['profanity_prob']\n",
    "        features = np.hstack((sentiment, profanity))\n",
    "        if index == 0:\n",
    "            feature_data[n] = features\n",
    "            score_data[n] = row['score']\n",
    "        else:\n",
    "            feature_data[n] = np.vstack([feature_data[n], features])\n",
    "            score_data[n] = np.vstack([score_data[n], row['score']])\n",
    "            \n",
    "    X_train_tmp, X_test_tmp, y_train_tmp, y_test_tmp = train_test_split(feature_data[n], score_data[n], test_size=0.20, random_state=42)\n",
    "    X_train.append(X_train_tmp)\n",
    "    X_test.append(X_test_tmp)\n",
    "    y_train.append(y_train_tmp)\n",
    "    y_test.append(y_test_tmp)\n",
    "\n",
    "    X_train[n] = tf.keras.utils.normalize(X_train[n], axis=1)\n",
    "    X_test[n] = tf.keras.utils.normalize(X_test[n], axis=1)\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we can do some neural networks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(24, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-138698ac3ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_number = 1\n",
    "\n",
    "train_data = X_train[test_number]\n",
    "test_data = X_test[test_number]\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    y_train[test_number],\n",
    "                    epochs=40,\n",
    "                    validation_data=(test_data, y_test[test_number]),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
